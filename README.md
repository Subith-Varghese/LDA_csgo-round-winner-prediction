# ğŸ† CSGO Round Winner Prediction ğŸ¯

Predict the winning team (CT or T) in Counter-Strike: Global Offensive (CSGO) rounds using Machine Learning.
This project leverages LDA-based feature selection and compares Logistic Regression, Decision Tree, and Random Forest classifiers to deliver accurate predictions.
We implemented data preprocessing, feature selection, model training, evaluation, and prediction pipelines to build an end-to-end ML solution.

---
ğŸ“‚ Dataset
- File: DataCGGO.csv
- Rows: 122,410
- Columns: 97
- Target Column: round_winner
- Includes player stats, weapons, grenades, money, and map details.
---

ğŸ—‚ Project Structure
```
CSGO_Round_Winner_Prediction/
â”‚â”€â”€ data/
â”‚   â””â”€â”€ DataCGGO.csv                # Dataset
â”‚
â”‚â”€â”€ notebooks/
â”‚   â””â”€â”€ model_notebook.ipynb        # Initial EDA & model experiments
â”‚
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py       # Data loading, encoding, scaling
â”‚   â”œâ”€â”€ feature_selection.py        # LDA-based feature selection
â”‚   â”œâ”€â”€ model_training.py           # Train models & save artifacts
â”‚   â”œâ”€â”€ model_evaluation.py         # Evaluate models & generate reports
â”‚   â”œâ”€â”€ predict.py                  # Predict on new data
â”‚   â”œâ”€â”€ logger.py                  # Central logging utility
â”‚
â”‚â”€â”€ artifacts/
â”‚   â”œâ”€â”€ lda_model.pkl              # Saved LDA model
â”‚   â”œâ”€â”€ scaler.pkl                 # StandardScaler
â”‚   â”œâ”€â”€ label_encoders.pkl         # Encoders for categorical data
â”‚   â”œâ”€â”€ LogisticRegression_model.pkl
â”‚   â”œâ”€â”€ DecisionTree_model.pkl
â”‚   â”œâ”€â”€ RandomForest_model.pkl
â”‚
â”‚â”€â”€ logs/                          # Logs for debugging & monitoring
â”‚â”€â”€ main.py                        # Pipeline entry point
â”‚â”€â”€ requirements.txt               # Python dependencies
â”‚â”€â”€ README.md                      # Project documentation
â”‚â”€â”€ .gitignore                     # Ignore unnecessary files

```
---

## Project Workflow

### Step 1 â€” Data Preprocessing
File: src/data_preprocessing.py
  - Load dataset
  - Handle duplicates
  - Label encode bomb_planted & map
  - Standardize features using StandardScaler
  - Save label encoders & scaler in artifacts/

---

### Step 2 â€” Feature Selection
File: src/feature_selection.py
  - Apply Linear Discriminant Analysis (LDA)
  - Compute feature importance using coefficients
  - Select top 20 most important features for modeling

--- 

### Step 3 â€” Model Training
File: src/model_training.py
- Train 3 ML models:
  - Logistic Regression
  - Decision Tree
  - Random Forest
- Save trained models into artifacts/
  
---

### Step 4 â€” Model Evaluation

File: src/model_evaluation.py
- Evaluate models using:
  - Accuracy
  - Classification Report
  - Confusion Matrix
- Random Forest achieved the best performance (~85%)

---
### Step 5 â€” Prediction

File: src/predict.py
- Loads:
  - Trained models
  - LDA model
  - Scaler
  - Label encoders
- Preprocesses new unseen data
- Selects top 20 features
- Generates predictions for each model

---

## âš™ï¸ Installation

```
# Clone the repository
git clone https://github.com/your-username/CSGO_Round_Winner_Prediction.git

# Navigate to the project directory
cd CSGO_Round_Winner_Prediction

# Create a virtual environment
python -m venv venv

# Activate the virtual environment
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

```

---
## ğŸš€ Model Training

Run the entire ML pipeline:

```
python main.py
```
---
This will:
  - Preprocess data
  - Perform LDA-based feature selection
  - Train all models
  - Evaluate model performance
  - Save trained models & artifacts in artifacts/

---

## Prediction On New Data

Once models are trained, predict winners for new data:
```
python src/predict.py
```

This will:
  - Load the trained models & artifacts
  - Preprocess new data
  - Select top 20 LDA features
  - Generate predictions for Logistic Regression, Decision Tree, and Random Forest

---
## Results

| Model               | Accuracy    |
| ------------------- | ----------- |
| Logistic Regression | **75.8%**   |
| Decision Tree       | **80.7%**   |
| Random Forest       | **85.4%** âœ… |
